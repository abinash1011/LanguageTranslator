{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a62c9e-f2e2-49cc-94a8-41e90220aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5aeb95-58f1-493a-a9d2-e4161a35490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb18ffe-243b-4c5e-b79b-fb47e0b66bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data/Hindi/hin.txt',sep='\\t', header=None)\n",
    "df.columns =['english', \"hindi\", \"attribution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee414de-1c8a-4ef8-9ba0-a60b3111bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  hindi                                        attribution\n",
       "0    Wow!   वाह!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "1   Duck!  झुको!  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2   Duck!  बतख़!  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3   Help!  बचाओ!  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
       "4   Jump.  उछलो.  CC-BY 2.0 (France) Attribution: tatoeba.org #6..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86fec7d1-dae3-4663-bcea-6c77f3d4a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"attribution\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c24b4d-ab3e-49d1-8644-f8bf42338bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_hindi_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348d6adf-6d70-4426-a794-8389b1a521e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8dc483-29ab-4872-92d7-a214e4fc24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea27e036-8161-4320-89d1-189de0ebe6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, df, reverse=False):\n",
    "    '''\n",
    "    Read lines, from text file.\n",
    "    lang1 - laguage as input,\n",
    "    lang2 - output language,\n",
    "    df - dataframe\n",
    "    reverse - to reverse the languages as input and output.\n",
    "    '''\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # # Read the file and split into lines\n",
    "    # lines = open('Data/Hindi/hin.txt'.format(lang1, lang2), encoding='utf-8').\\\n",
    "    #     read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    \n",
    "    # pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    # pairs = [[z.split(\"\\t\") for z in normalizeString(f\"{x}\\t{y}\")] for x, y in zip(df[lang1], df[lang2])]\n",
    "    pairs = [[normalizeString(df[lang1][i]), normalizeString(df[lang2][i])] for i in df.index]\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd88ef1-d673-428c-8efc-1e86f07e2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15 #max length of words in a sentence.\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
    "        #p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b4e95b-fb35-49ae-8166-1be202609cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 2980 sentence pairs\n",
      "Trimmed to 2932 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "english 2474\n",
      "hindi 3062\n",
      "['we put sugar in our tea .', 'हम चाय में चीनी डालते हैं।']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, df, reverse=False):\n",
    "    '''\n",
    "    prepare class objects for the languages.\n",
    "    '''\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, df, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('english', 'hindi', df, False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d0a04-e61c-4446-bf25-761fd11c90ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b067491-67a5-4a04-8c7d-07887de81c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  hindi\n",
       "0    Wow!   वाह!\n",
       "1   Duck!  झुको!\n",
       "2   Duck!  बतख़!\n",
       "3   Help!  बचाओ!\n",
       "4   Jump.  उछलो."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da507f2-bc7b-44df-ad53-4b3a65e19d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25edb9a-f7ca-4db8-acf4-53d55e250c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b605985-961b-4ca0-ac7c-edde8a816887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63c0f35-325c-4d83-8831-bf03dc797351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91f92437-2674-4705-82d4-4bf8b2766e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4170a9d3-9138-4cdd-bd4f-21f1d9b0c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd17342-6914-4689-9146-77f0594e8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for i in tqdm.tnrange(1, n_iters + 1):\n",
    "        training_pair = training_pairs[i - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / n_iters),\n",
    "                                         i, i / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "782d67b5-a90b-4584-a124-bb42cd2d9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96e92f47-5a4e-46e2-b466-cbcc992b5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# def pad_sequence(sequence, max_length):\n",
    "#     # Pad sequence with zeros to match the max_length\n",
    "#     padded_sequence = torch.zeros((max_length, *sequence[0].shape), dtype=sequence[0].dtype)\n",
    "#     for i, tensor in enumerate(sequence):\n",
    "#         padded_sequence[i] = tensor\n",
    "#     return padded_sequence\n",
    "\n",
    "# def trainIters(encoder, decoder, n_iters, batch_size=1, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "#     global pairs  # Access the global pairs variable\n",
    "#     start = time.time()\n",
    "#     plot_losses = []\n",
    "#     print_loss_total = 0  # Reset every print_every\n",
    "#     plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "#     encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "#     decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "#                       for i in range(n_iters)]\n",
    "#     criterion = nn.NLLLoss()\n",
    "\n",
    "#     # Determine the maximum sequence length in the training pairs\n",
    "#     max_length = max(max(len(pair[0]), len(pair[1])) for pair in training_pairs)\n",
    "\n",
    "#     # Pad the training pairs to ensure equal sequence lengths within a batch\n",
    "#     padded_training_pairs = []\n",
    "#     for pair in training_pairs:\n",
    "#         padded_input = pad_sequence(pair[0], max_length)\n",
    "#         padded_target = pad_sequence(pair[1], max_length)\n",
    "#         padded_training_pairs.append((padded_input, padded_target))\n",
    "\n",
    "#     data_loader = DataLoader(padded_training_pairs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     for i in tqdm.notebook.tnrange(1, n_iters + 1):\n",
    "#         for batch in data_loader:\n",
    "#             input_tensor = batch[0].to(device)\n",
    "#             target_tensor = batch[1].to(device)\n",
    "\n",
    "#             loss = train(input_tensor, target_tensor, encoder,\n",
    "#                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "#             print_loss_total += loss.item()\n",
    "#             plot_loss_total += loss.item()\n",
    "\n",
    "#         if i % print_every == 0:\n",
    "#             print_loss_avg = print_loss_total / (print_every * batch_size)\n",
    "#             print_loss_total = 0\n",
    "#             print('%s (%d %d%%) %.4f' % (timeSince(start, i / n_iters),\n",
    "#                                          i, i / n_iters * 100, print_loss_avg))\n",
    "\n",
    "#         if i % plot_every == 0:\n",
    "#             plot_loss_avg = plot_loss_total / (plot_every * batch_size)\n",
    "#             plot_losses.append(plot_loss_avg)\n",
    "#             plot_loss_total = 0\n",
    "\n",
    "#     showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e126fbf5-c64e-481e-895a-39a1eaf42387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf7f5c7-0cd5-48ff-8745-de6ff207d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9cce571-295e-4b7f-b026-dd3dd06f27c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51f74efbc674568a7ec94b146d326b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 30s (- 9m 50s) (4000 13%) 4.8027\n",
      "2m 59s (- 8m 12s) (8000 26%) 3.9177\n",
      "4m 29s (- 6m 43s) (12000 40%) 3.0630\n",
      "6m 0s (- 5m 15s) (16000 53%) 2.3230\n",
      "7m 32s (- 3m 46s) (20000 66%) 1.7484\n",
      "9m 6s (- 2m 16s) (24000 80%) 1.3059\n",
      "11m 25s (- 0m 48s) (28000 93%) 0.9828\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 30000, print_every=4000, plot_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "325d83e3-1eda-49c6-952b-7aa2cd101aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), 'encoder_model.pth')\n",
    "torch.save(attn_decoder1.state_dict(), 'attn_decoder_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e322b900-9983-4bac-91eb-2e82719ffaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load saved models\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "# encoder1.load_state_dict(torch.load('encoder_model.pth'))\n",
    "\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "# attn_decoder1.load_state_dict(torch.load('decoder_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5128021-10b8-4e49-bcd3-bde80406e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> she's not a doctor .\n",
      "= वह डॉक्टर नहीं है।\n",
      "< करवाया ताज़ा जीन्स जीन्स भूत-प्रेत भूत-प्रेत भूत-प्रेत चीज़ें माथे चीज़ें तोड़ और-भी-और ईनाम होने जूतों\n",
      "\n",
      "> the fisherman exaggerated the size of the fish he had caught .\n",
      "= मछवारे ने पकड़ी हुई मछली के आकार को बढ़ा-चढ़ाकर बताया।\n",
      "< ताज़ा ताज़ा जीन्स जीन्स जीन्स भूत-प्रेत भूत-प्रेत गईं। आकार प्रकार बीमारी समझिए। माथे माथे चौड़ी\n",
      "\n",
      "> place it wherever you like .\n",
      "= जहाँ भी रखना है रखदो।\n",
      "< कौनसे ताज़ा रखो कूदो। जीन्स पकड़कर धर्म पकड़कर धर्म पकड़कर धर्म ये ये ये ये\n",
      "\n",
      "> can you teach me ?\n",
      "= क्या तुम मुझे सिखा सकते हो ?\n",
      "< बस्ता आकार घुसा। माथे माथे माथे माथे चौड़ी नकल कमरा भूत-प्रेत भूत-प्रेत चीज़ें पृष्ठ क़त्ल\n",
      "\n",
      "> nothing is better than ice cream in the summer .\n",
      "= गर्मी में आइसक्रीम से बेहतर कुछ नहीं।\n",
      "< माथे माथे माथे माथे माथे माथे माथे \"कैसे\" आकार ताज़ा फ़्लैट फ़्लैट साढ़े-आठ और-भी-और विलोम\n",
      "\n",
      "> i can teach english .\n",
      "= मैं अंग्रेज़ी पढ़ा सकता हूँ।\n",
      "< रखो जीन्स जीन्स लंदन कुत्ते कुत्ते हल्का बचाए। ही। संदेश करो प्रकार आधा भूत-प्रेत भूत-प्रेत\n",
      "\n",
      "> buddhism had its beginnings in india .\n",
      "= बौद्ध धर्म भारत में पैदा हुआ था।\n",
      "< ताज़ा ताज़ा ताज़ा प्रदूषित ये ये ये पकड़कर घंटों घंटों घंटों घंटों फिरसे लाऊँगा। छूट\n",
      "\n",
      "> i'm thinking of changing jobs .\n",
      "= मैं नौकरी बदलने की सोच रही हूँ।\n",
      "< ताज़ा ताज़ा रहेगा। जीन्स पकड़कर घंटों घंटों एलर्जी पाय जीन्स जीन्स भूत-प्रेत जीन्स जीन्स क्षमा\n",
      "\n",
      "> i will never forget your kindness so long as i live .\n",
      "= मैं आपकी अच्छाई को कभी नहीं भूलूँगा।\n",
      "< ताज़ा ताज़ा जीन्स जीन्स जीन्स भूत-प्रेत जीन्स भूत-प्रेत भूत-प्रेत चीज़ें जीन्स भूत-प्रेत भूत-प्रेत चीज़ें माथे\n",
      "\n",
      "> i can't put up with his arrogance .\n",
      "= मुझसे उसका अक्खड़पन झेला नहीं जाता।\n",
      "< कौनसे माथे माथे माथे माथे माथे माथे माथे चौड़ी नकल कमरा से उतार खिलाना माथे\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1c6b57c-7b81-4e0f-8a13-414fe55e099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_input(encoder, decoder, text):\n",
    "    print('>', text)\n",
    "    output_words, attentions = evaluate(encoder, decoder, text)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c100863-37b1-4729-ae09-ffafd31b8354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> my wife really hates cats .\n",
      "< इसलिए ताज़ा रखो कूदो। जीन्स भूत-प्रेत भूत-प्रेत लम्बीं चीज़ें माथे माथे चीज़ें माथे माथे कुछ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_input(encoder1, attn_decoder1, \"my wife really hates cats .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2be406-8157-4539-9fc1-4e7bf200a8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9af8d-000d-409d-a5ee-c5108ea8fe85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ca026-e9c3-453c-af41-ab75f942c4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e4cb9-917a-4c01-9d29-5f602f489372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02c084-0e21-4909-980f-652cf64868b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85152240-144e-4533-8f7b-0df6c43b06e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da212e5-a47d-4b16-9d4d-ad488c64dbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92f7d8-7f4d-471e-992d-f47591217f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef276502-a04a-4c5c-9f26-dbf62cf2e49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fdead-1be0-4a6f-8be3-e55c2470ab94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa568002-9424-44ed-bd77-6ff4f3497ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333f696-2b70-4eaa-8c89-0631dc4fa90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d200efe-42a0-484a-b091-8acafa7bae97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8881d8-5f5e-4169-a280-3bdf8d63f5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a205c6-4102-4823-8187-b7a86306d5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727e92b-2d18-4dcf-aebb-3ea05cb8e7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae5f3f-5012-46cc-ab1f-f33377e67b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b90068-6183-4d8f-ac72-e7266b40d1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078f127-1ac0-4567-a79a-be9bdf31846b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c8e61-f9ce-4460-b510-cab551da3327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89147afa-d409-4600-afc0-d02be8c83793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5972488-4298-40a6-a7a2-5fd6eb8a593c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815931d6-f289-46ab-a4b0-a29dd6ed84c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79db83-7625-4469-b769-8355b970ca96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344216fc-3fab-4614-bef0-b2db3130fd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9ffe3-1b1f-48cf-8eae-e00bb2842811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa869035-32ee-4e9a-801e-5e786748b60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f25a58-da15-41d3-8410-8293afa5066b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94f8f3-bdaa-468c-b493-8ce96f23122c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d783c4e-f672-41d9-9602-b7304047eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d5b5d-4c69-423b-80ce-36994732002e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1473008-13e7-47c3-87e6-ef1546e9099b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76970d6-bcfd-400e-947a-c97772f00922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6788ea-ba48-4eb9-b22e-34decc2e29bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44524821-17ce-4345-8008-dc7ece06c945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dde00-376f-4fa5-8913-c114f70edacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80076a3-37c7-4247-98d7-99f1f7371d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ce6dd-609d-4365-95ba-bdad3975d60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29b91b-3274-4425-9fb5-a8074efe3975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4b020-1426-428d-8f5a-dc9cac8c8244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7aca20-2132-409d-a546-76cb1aba4240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c860b1d-defa-40de-ba02-e334ac375b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b186f3-8389-4a30-8d8d-320983a8a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd24b2-06fe-443d-b84d-1d7a42b4b1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291c5c0-e85f-477c-94f1-eee344fd5579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af81bf-c585-4246-8e9d-ce837a69c7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ada7f-c0fc-4d4e-97f6-d22e7d90d2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde01b2-635d-4ab3-8e7c-55b3411fc124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514039b2-668e-480c-a191-a83186396b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af3724-a45d-4734-9b3a-3a9cfdb73545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba780b-88f4-4a38-aa61-62665a36786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9349c02-2b1e-4b40-a9ba-966f5ad5d478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b5e5e-327a-4c94-aa99-1c4b01008b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a5195-e897-44f1-b240-1dddf947d835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37b517-172b-4907-9677-a85e031bb742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16ea52-7c66-4420-a2c5-c5bc686ef950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984e2c4-c4b2-48f0-9607-0fe7ba82b97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e41484-6faf-4f03-9996-921e50a18016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33f6e3-b656-4b8a-8ee2-c2177b74b6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439b2b8-95c3-437b-8703-4f34ed6e973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7197cb5-0174-4fc4-ac7e-6517b6cbd9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1edbcf-8e9e-4fd0-9691-97aceb3d0fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889ac05-39c3-4267-8b52-d1a7f1264d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd9c1d-33c9-4075-93b0-adaa02975e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3a4f0-2623-453a-ab80-2309ec9f1a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527b5b6-ed79-488b-b264-f9882be23aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9df07c-3e97-472b-a297-37f60bd6e231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787b6e8-5243-425c-9edd-f707a9cc35be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783eb3c-c9bd-46a7-bbd7-988b83fe9c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bca584-2344-4be6-9166-0c359074f69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456bd18c-8ae4-46fa-86d5-4c337602d385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b043a-c75f-42e1-a3c2-561cc4fe2bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c86b6-ec65-4e93-977e-04fc5e0af3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47165cfe-1b65-45a0-bf4b-61bd7f5ec658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65454b4-ff20-4ff2-9d9c-291c8bed319d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1df1a6-cede-4392-8b3a-8489c58f9365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bc997-2509-4e5b-98fe-c0af86ab2eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98e67a-51d2-422b-8d4f-a5a9173e1079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee1a36-6a4e-4e7f-98c6-0e79633142fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5987b6-9a2e-40a3-9b38-a458d93f95d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb38bff-1d71-4a67-9211-6a1c361145d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71f622-3fc6-4bdf-bc81-ea872f27d5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a562b-56d4-4d78-b401-2b0b2804ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003eb3a-b41b-4f2d-abea-fab1ecb4ae3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afcc99-9ded-4ab6-94c1-ca52f4a7eadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212375c-2628-4e77-b991-71a598668613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe3710-e316-4f7a-adf4-9d7547fca2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a63e0-eb50-491d-a02c-07da23db7aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314e13b-d9b0-49bd-b494-53fe992a8820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fde06-acd0-458e-bf59-898f09fc67f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62c249-b033-4f35-8e8a-7392db9b8451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005f194-af01-493b-b1a7-b6f6f2861c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86fa91-4099-4559-b426-3a623276e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe16f6-912b-4e15-9cf3-4847e8cba005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb15a65-59b1-4da6-aa80-f5b5edbed78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a1971-2bfc-4b38-9f1f-1d0c8d113295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb317e76-649a-40ca-b9c3-5272a3062657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6b090-0cbf-4084-8d33-c4b08b81e497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdce33-cc3f-486b-af63-311728a42fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c45f7-0da6-4d9f-9f47-3203fd5838ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8c7af-0807-4422-93d1-a42a0120cdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff4660-df93-43b9-a621-afa96d01c694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57fc53-4a2c-4fbc-b27a-a98e338f2fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "lang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
